{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training our first feedforward NN, we will use the in built datasets, in this case the popular MNIST dataset. $torchvision.datasets$ contains several popular datasets like MNIST, Fashion-MNIST, EMNIST, CIFAR etc.\n",
    "\n",
    "$torchvision.transforms$ contains common image transforms that we will need for the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let us import the training and test data from MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will get saved in the $data$ folder and their processed forms will be stored in the $data/processed$ folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is setting up the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input is 28x28 pixels = 784 (since single channel)\n",
    "input_size = 784\n",
    "# The number of hidden layers may be emperically chosen but we set our best estimate to begin with\n",
    "hidden_size = 500\n",
    "# 10 classes since 10 digits\n",
    "num_classes = 10\n",
    "# Let us train it for 10 epochs i.e. 10 training cycles\n",
    "num_epochs = 10\n",
    "# Depending on how powerful your machine is you can increase the batch size\n",
    "batch_size = 100\n",
    "# To avoid overfitting, we start with a low learning rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have procured the data and set the hyperparameters, we will set up a pipeline for the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preparation phase is over, we have the data, a configured pipeline and now we will create the model. For simplicity we will create a single layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on creating your first model. Go ahead and experiment with the __learning rate__, __hidden layer size__, __batch size__ and __number of epochs__ once you are done to understand how they affect your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:87: UserWarning: \n",
      "    Found GPU0 GeForce GTX 1060 with Max-Q Design which requires CUDA_VERSION >= 8000 for\n",
      "     optimal performance and fast startup time, but your PyTorch was compiled\n",
      "     with CUDA_VERSION 7050. Please install the correct PyTorch binary\n",
      "     using instructions from http://pytorch.org\n",
      "    \n",
      "  warnings.warn(error_str % (d, name, 8000, CUDA_VERSION))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transfered the NN to the GPU using $net.cuda()$. Also note that we used a fully connected layer and the outermost layers and used a ReLU activation in the hidden layer.\n",
    "\n",
    "Now that we have our model we need to decide what loss function we want to use and the optimizer that will minimize our loss function. We choose the Cross Entropy (or log) loss function and the [Adam Optimizer](https://arxiv.org/abs/1412.6980v8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the data i.e. we iterate over the test data and pass it to the model. We calculate loss, backpropagate and then try to optimize our loss function.\n",
    "\n",
    "A common practice while training is to print the status and the value of the loss after every $n$ steps. Here we choose $100$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get an estimate of how long this process takes using the $time$ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.3295\n",
      "Epoch [1/10], Step [200/600], Loss: 0.1577\n",
      "Epoch [1/10], Step [300/600], Loss: 0.2016\n",
      "Epoch [1/10], Step [400/600], Loss: 0.2591\n",
      "Epoch [1/10], Step [500/600], Loss: 0.2471\n",
      "Epoch [1/10], Step [600/600], Loss: 0.1076\n",
      "Epoch [2/10], Step [100/600], Loss: 0.1606\n",
      "Epoch [2/10], Step [200/600], Loss: 0.1400\n",
      "Epoch [2/10], Step [300/600], Loss: 0.0607\n",
      "Epoch [2/10], Step [400/600], Loss: 0.1162\n",
      "Epoch [2/10], Step [500/600], Loss: 0.0700\n",
      "Epoch [2/10], Step [600/600], Loss: 0.1095\n",
      "Epoch [3/10], Step [100/600], Loss: 0.0613\n",
      "Epoch [3/10], Step [200/600], Loss: 0.0401\n",
      "Epoch [3/10], Step [300/600], Loss: 0.0401\n",
      "Epoch [3/10], Step [400/600], Loss: 0.0181\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0543\n",
      "Epoch [3/10], Step [600/600], Loss: 0.0765\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0500\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0591\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0197\n",
      "Epoch [4/10], Step [400/600], Loss: 0.0195\n",
      "Epoch [4/10], Step [500/600], Loss: 0.1489\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0470\n",
      "Epoch [5/10], Step [100/600], Loss: 0.0133\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0381\n",
      "Epoch [5/10], Step [300/600], Loss: 0.0225\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0154\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0404\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0600\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0405\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0066\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0452\n",
      "Epoch [6/10], Step [400/600], Loss: 0.0422\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0354\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0114\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0238\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0163\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0072\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0041\n",
      "Epoch [7/10], Step [500/600], Loss: 0.0226\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0066\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0120\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0053\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0302\n",
      "Epoch [8/10], Step [400/600], Loss: 0.0117\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0038\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0047\n",
      "Epoch [9/10], Step [100/600], Loss: 0.0014\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0040\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0105\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0952\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0045\n",
      "Epoch [9/10], Step [600/600], Loss: 0.0311\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0072\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0059\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0018\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0033\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0230\n",
      "Epoch [10/10], Step [600/600], Loss: 0.0150\n",
      "58.2868070602417\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Convert torch tensor to Variable for calculations\n",
    "        images = Variable(images.view(-1, 28*28).cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 epochs we get a loss of $0.015$ and the overall training time was $58$ seconds. \n",
    "\n",
    "Note: Total number of steps = size_of_dataset / batch_size \n",
    "\n",
    "Congratualtions on training your first model with an image dataset. No go ahead and test the model's performance and repeat this process after changing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28)).cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finally satisfied with your results you can even save your model for future use as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mnist_fnn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
