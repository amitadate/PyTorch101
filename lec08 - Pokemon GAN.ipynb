{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Vanilla Generative Adversarial Network'''\n",
    "\n",
    "# disciminator network\n",
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.ndf = 32\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, self.ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf, self.ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 2, self.ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 4, self.ndf * 8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(self.ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(self.ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# generator network \n",
    "class G(nn.Module):\n",
    "    def __init__(self, latent):\n",
    "        super(G, self).__init__()\n",
    "        self.ngf = 32\n",
    "        self.latent = latent\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.latent, self.ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 8, self.ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 4, self.ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf * 2, self.ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(self.ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom pytorch dataset\n",
    "class PokeDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root = root_dir\n",
    "        self.tform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.dirname(\"\")\n",
    "        working_dir = os.path.join(file, self.root)\n",
    "        imname = str(idx+1) + '.png'\n",
    "        impath = os.path.join(working_dir, imname)\n",
    "        tmp_imp = Image.open(impath)\n",
    "        # remove alpha channel\n",
    "        img_rgb = Image.new('RGB', tmp_imp.size, color=(255, 255, 255))\n",
    "        img_rgb.paste(tmp_imp, mask=tmp_imp.split()[3])\n",
    "        img_64rgb = img_rgb.resize((64,64))\n",
    "        return self.tform(img_64rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.0001\n",
    "torch.manual_seed(12345)\n",
    "batch_size = 64\n",
    "use_cuda = torch.cuda.is_available()\n",
    "latent_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PokeDataset('./data/pokemon')\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True, num_workers=2)\n",
    "discriminator = D()\n",
    "generator = G(latent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "           ...             ⋱             ...          \n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "  1.0000  1.0000  1.0000  ...   1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x64x64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found and active\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:87: UserWarning: \n",
      "    Found GPU0 GeForce GTX 1060 with Max-Q Design which requires CUDA_VERSION >= 8000 for\n",
      "     optimal performance and fast startup time, but your PyTorch was compiled\n",
      "     with CUDA_VERSION 7050. Please install the correct PyTorch binary\n",
      "     using instructions from http://pytorch.org\n",
      "    \n",
      "  warnings.warn(error_str % (d, name, 8000, CUDA_VERSION))\n"
     ]
    }
   ],
   "source": [
    "# loss(o, t) = - 1/n \\sum_i (t[i] log(o[i]) + (1 - t[i]) log(1 - o[i]))\n",
    "loss = nn.BCELoss(size_average=True)\n",
    "\n",
    "if use_cuda:\n",
    "    print('CUDA device found and active')\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()\n",
    "    loss.cuda()\n",
    "\n",
    "# optimizers\n",
    "optimD = optim.Adam(discriminator.parameters(), lr, betas=(0.5, 0.999))\n",
    "optimG = optim.Adam(generator.parameters(), lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0]/[1000]    lossD 1.32882    lossG 0.89517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type D. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type G. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [100]/[1000]    lossD 0.76900    lossG 5.91544\n",
      "epoch [200]/[1000]    lossD 0.28005    lossG 2.99047\n",
      "epoch [300]/[1000]    lossD 4.48831    lossG 11.28469\n",
      "epoch [400]/[1000]    lossD 0.07096    lossG 3.68977\n",
      "epoch [500]/[1000]    lossD 0.06381    lossG 4.38413\n",
      "epoch [600]/[1000]    lossD 0.03484    lossG 4.45693\n",
      "epoch [700]/[1000]    lossD 0.04137    lossG 4.47763\n",
      "epoch [800]/[1000]    lossD 0.03775    lossG 4.56968\n",
      "epoch [900]/[1000]    lossD 0.19890    lossG 14.35035\n"
     ]
    }
   ],
   "source": [
    "print_every = 100\n",
    "im_samples_every = 100\n",
    "\n",
    "test_noise = torch.Tensor(batch_size, latent_size, 1, 1).normal_(0, 1)\n",
    "if use_cuda:\n",
    "    test_noise = test_noise.cuda()\n",
    "\n",
    "test_noiseV = Variable(test_noise)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for j, data in enumerate(dataloader):\n",
    "        latent = torch.Tensor(data.size(0), latent_size, 1, 1)\n",
    "        label = torch.Tensor(data.size(0), 1, 1, 1)\n",
    "\n",
    "        if use_cuda:\n",
    "            latent = latent.cuda()\n",
    "            label = label.cuda()\n",
    "            data = data.cuda()\n",
    "\n",
    "        # train discriminator        \n",
    "        # train on real\n",
    "        # input an image, 0|1 if fake|real        \n",
    "        optimD.zero_grad()\n",
    "        real_label = Variable(label.fill_(1), requires_grad=False)\n",
    "        real_im = Variable(data, requires_grad=False)\n",
    "\n",
    "        out = discriminator(real_im)\n",
    "        loss_real = loss(out, real_label)\n",
    "        loss_real.backward()\n",
    "\n",
    "        # train D on fake\n",
    "        noise = Variable(latent.normal_(0, 1), requires_grad=False)\n",
    "        fake_label = Variable(label.fill_(0), requires_grad=False)\n",
    "\n",
    "        fake = generator(noise)\n",
    "        out = discriminator(fake.detach())\n",
    "        loss_fake = loss(out, fake_label)\n",
    "        loss_fake.backward()\n",
    "        optimD.step()\n",
    "\n",
    "        # train generator\n",
    "        fake_real_label = Variable(label.fill_(1), requires_grad=False)       \n",
    "        optimG.zero_grad()\n",
    "        out = discriminator(fake)\n",
    "        loss_gen = loss(out, fake_real_label)\n",
    "        loss_gen.backward()\n",
    "        optimG.step()\n",
    "        \n",
    "        if i % print_every == 0 and j % 12 == 0:\n",
    "            print('epoch [{}]/[{}]    lossD {:.5f}    lossG {:.5f}'.format(\n",
    "                    i, epochs, (loss_real.cpu().data[0] + loss_fake.cpu().data[0]), \n",
    "                    loss_gen.cpu().data[0]))\n",
    "\n",
    "        if i % im_samples_every == 0:\n",
    "            out = generator(test_noiseV).cpu().data\n",
    "            utils.save_image(out, './data/fake/fake'+str(i//im_samples_every)+'.jpg', normalize=True)\n",
    "            torch.save(discriminator, 'poke_dis.pkl')\n",
    "            torch.save(generator, 'poke_gen.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type D. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/hemant/anaconda3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type G. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(discriminator, 'poke_dis.pkl')\n",
    "torch.save(generator, 'poke_gen.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
